{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63a7cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libreria para gestionar archivos\n",
    "import os\n",
    "# Libreria para trabajar con redes neuronales convolucionales\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "# Libreria para trabajar con imagenes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbda86ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo imagenes de  c:\\Users\\yjot2\\Downloads\\RNC\\Data\\\n",
      "c:\\Users\\yjot2\\Downloads\\RNC\\Data\\amarillo 1\n",
      "c:\\Users\\yjot2\\Downloads\\RNC\\Data\\blanco 1000\n",
      "c:\\Users\\yjot2\\Downloads\\RNC\\Data\\gris 1000\n",
      "c:\\Users\\yjot2\\Downloads\\RNC\\Data\\marron 1000\n",
      "c:\\Users\\yjot2\\Downloads\\RNC\\Data\\rojo 1000\n",
      "Directorios leidos: 5\n",
      "Imagenes en cada directorio [1001, 1000, 1000, 1000, 999]\n",
      "Suma Total de imagenes en subdirs: 5000\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "dirname = os.path.join(os.getcwd(), 'Data')\n",
    "imgpath = dirname + os.sep \n",
    " \n",
    "images = []\n",
    "directories = []\n",
    "dircount = []\n",
    "prevRoot=''\n",
    "cant=0\n",
    " \n",
    "print(\"Leyendo imagenes de \",imgpath)\n",
    " \n",
    "for root, dirnames, filenames in os.walk(imgpath):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant=cant+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            images.append(image)\n",
    "            b = \"Leyendo...\" + str(cant)\n",
    "            print (b, end=\"\\r\")\n",
    "            if prevRoot !=root:\n",
    "                print(root, cant)\n",
    "                prevRoot=root\n",
    "                directories.append(root)\n",
    "                dircount.append(cant)\n",
    "                cant=0\n",
    "dircount.append(cant)\n",
    " \n",
    "dircount = dircount[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('Suma Total de imagenes en subdirs:',sum(dircount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cca19fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad etiquetas creadas:  5000\n",
      "0 amarillo\n",
      "1 blanco\n",
      "2 gris\n",
      "3 marron\n",
      "4 rojo\n",
      "Total number of outputs :  5\n",
      "Output classes :  [0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "indice=0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)\n",
    "    indice=indice+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels))\n",
    " \n",
    "deportes=[]\n",
    "indice=0\n",
    "archivoTxt = open(\".\\Model\\labels.txt\", \"w\")\n",
    "for directorio in directories:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice , name[len(name)-1])\n",
    "    deportes.append(name[len(name)-1])\n",
    "    # Crear archivo TXT de etiquetas\n",
    "    archivoTxt.write(name[len(name)-1])\n",
    "    archivoTxt.write(\"\\n\")\n",
    "    indice=indice+1\n",
    "archivoTxt.close()\n",
    " \n",
    "y = np.array(labels)\n",
    "X = np.array(images, dtype=np.uint8) # convierto de lista a numpy\n",
    " \n",
    "# Find the unique numbers from the train labels\n",
    "clases = np.unique(y)\n",
    "nClases = len(clases)\n",
    "print('Total number of outputs : ', nClases)\n",
    "print('Output classes : ', clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a6e8f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (3500, 200, 200, 3) (3500,)\n",
      "Testing data shape :  (1500, 200, 200, 3) (1500,)\n",
      "Original label: 1\n",
      "After conversion to one-hot: [0. 1. 0. 0. 0.]\n",
      "(2450, 200, 200, 3) (1050, 200, 200, 3) (2450, 5) (1050, 5)\n"
     ]
    }
   ],
   "source": [
    "# Mezclar todo y crear los grupos de entrenamiento y testing\n",
    "porcentajeTest = 0.3\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=porcentajeTest)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)\n",
    " \n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255.\n",
    " \n",
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    " \n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])\n",
    " \n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=porcentajeTest, random_state=13)\n",
    " \n",
    "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c09e0af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 200, 200, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 100, 100, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 100, 100, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 50, 50, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 50, 50, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 25, 25, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 25, 25, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 12, 12, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 12, 12, 512)       1180160   \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 6, 6, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 6, 6, 1024)        2098176   \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 3, 3, 1024)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               921700    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 505       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,609,157\n",
      "Trainable params: 4,609,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 131s 7s/step - loss: 1.5251 - accuracy: 0.2678 - val_loss: 1.3745 - val_accuracy: 0.5895\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 134s 7s/step - loss: 1.3487 - accuracy: 0.3943 - val_loss: 1.0651 - val_accuracy: 0.7876\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 135s 7s/step - loss: 1.1524 - accuracy: 0.4792 - val_loss: 0.7012 - val_accuracy: 0.7876\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 134s 7s/step - loss: 0.9248 - accuracy: 0.5935 - val_loss: 0.4440 - val_accuracy: 0.7876\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 135s 7s/step - loss: 0.7547 - accuracy: 0.6702 - val_loss: 0.3331 - val_accuracy: 0.8276\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 132s 7s/step - loss: 0.6282 - accuracy: 0.7347 - val_loss: 0.3013 - val_accuracy: 0.9990\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 136s 7s/step - loss: 0.5589 - accuracy: 0.7580 - val_loss: 0.2624 - val_accuracy: 0.9990\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 135s 7s/step - loss: 0.5007 - accuracy: 0.7865 - val_loss: 0.2355 - val_accuracy: 0.9990\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 136s 7s/step - loss: 0.4510 - accuracy: 0.8171 - val_loss: 0.1515 - val_accuracy: 0.9990\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 135s 7s/step - loss: 0.4206 - accuracy: 0.8371 - val_loss: 0.1464 - val_accuracy: 0.9990\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\yjot2\\AppData\\Local\\Temp\\tmp9krj36mj\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yjot2\\AppData\\Local\\Temp\\tmp9krj36mj\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo convertido a tflite exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Parametros\n",
    "epocas = 10 # Numero de iteraciones para aprender y predecir la data \n",
    "longitud, altura = 200, 200 # Tamano de imagenes a procesar en px\n",
    "batch_size = 128 # Ran go de imagenes a analizar por cada paso (entrenamiento y validacion)\n",
    "tamano_pool = (2, 2) # Tamano de matriz de caracteristicas especificas\n",
    "lr = 0.0001 # Tasa de aprendizaje\n",
    "\n",
    "cnn = Sequential()\n",
    "# Extraccion de caracteristicas generales y especificas #1 \n",
    "cnn.add(Convolution2D(32, (3, 3), padding=\"same\", input_shape=(longitud, altura, 3)))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "# Extraccion de caracteristicas generales y especificas #2\n",
    "cnn.add(Convolution2D(64, (3, 3), padding=\"same\"))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "# Extraccion de caracteristicas generales y especificas #3\n",
    "cnn.add(Convolution2D(128, (3, 3), padding=\"same\"))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "# Extraccion de caracteristicas generales y especificas #4\n",
    "cnn.add(Convolution2D(256, (3, 3), padding=\"same\"))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "# Extraccion de caracteristicas generales y especificas #5\n",
    "cnn.add(Convolution2D(512, (3, 3), padding=\"same\"))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "# Extraccion de caracteristicas generales y especificas #6\n",
    "cnn.add(Convolution2D(1024, (2, 2), padding=\"same\"))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "# Aplanado de imagenes, capa full conectada y aprendizaje por vias aleatorias\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(100, activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(100, activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(100, activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "# Capa full conectada final\n",
    "cnn.add(Dense(nClases, activation='softmax'))\n",
    "\n",
    "cnn.summary() # Ver resumen de la estructura de capas\n",
    "\n",
    "# Indicaciones de perdida, ganancia, optimizacion y entrenamiento del modelo\n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizers.Adam(learning_rate=lr),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "salida = cnn.fit(train_X, train_label, batch_size=batch_size,epochs=epocas,verbose=1,validation_data=(valid_X, valid_label))\n",
    "\n",
    "#Guardado del modelo keras\n",
    "target_dir = os.path.join(os.getcwd(), 'Model')\n",
    "if not os.path.exists(target_dir):\n",
    "  os.mkdir(target_dir)\n",
    "cnn.save(target_dir + '\\modelo.h5')\n",
    "#Conversion a un modelo TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(cnn)\n",
    "tflite_model = converter.convert()\n",
    "with open('.\\Model\\model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "print('Modelo convertido a tflite exitosamente')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
